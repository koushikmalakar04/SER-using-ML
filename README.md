# Speech_Emotion_Recognition-using-ML
Speech Emotion Recognition (SER) is a field of study that focuses on detecting and understanding human emotions from speech signals. It involves analyzing the acoustic features of speech to classify the underlying emotional state of the speaker. Machine Learning techniques, such as Multilayer Perceptron (MLP), can be employed to develop models for speech emotion recognition.

Steps:
1.  Data Collection : Collect the dataset. Here I use TESS(Toronto Emotional Speech Set) Dataset.
  
2.  Feature Extraction : Extract relevant acoustic features from the speech signals. I have use Mfcc(Mel-frequency cepstral       coefficients)
  
3.  Splitting : Split data into two parts Train data and Test data.

4.  Add Classifier : Here I use MLP(Multilayer Perceptron). The Multilayer Perceptron (MLP) is a type of artificial neural network that consists of multiple layers of interconnected nodes, known as neurons.

5.  Prediction: Once the model is trained and evaluated, it can be used to predict the emotional states of unseen speech samples.
